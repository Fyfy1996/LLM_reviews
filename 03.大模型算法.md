## 1.在指令微调中，如何设置、选择和优化不同的超参数，以及其对模型效果的影响？

无明确定论，总结一下分类别下的参数

* 数据集
  * drop-last
* 模型本身
* 训练设置
  * batchsize
  * clip grad
  * lr rate
  * weight decay
  * loss scale
  * warm up iters
  * lr decay style
  * lr decay iters





## 2.在指令微调中，如何选择最佳的指令策略，以及其对模型效果的影响？

总的来说，你需要先明确自己需要向什么方面微调：是一个更对齐人类价值观的gossip bot？还是更具备解决问题能力的helper？是更健谈并回答内容更丰富？还是人狠话不多？是单领域？还是多领域？

a.数据需要什么样的？

b.该如何组织数据集来微调？

首先是一些已知的要点：

Flanv2提到的一些tricks【待补充】

* 更多样的任务-使用不同的提示模板
* 混合few-shot和zero-shot learning
* 考虑输入反转
* 加入CoT
* 任务混合权重按照经验考虑即可

下面是数据集组织的方法论：

c.该如何评估sft后的model的能力？

## 3.llama, glm，bloom等现有大模型的数据处理，训练细节，以及不足之处模型架构的优化点，包括但不限于attention, norm, embedding

### LLAMA


**4.解决显存不够的方法有哪些？**

**5.请解释P-tuning 的工作原理，并说明它与传统的 fine-tuning方法的不同之处。**

**6.介绍一下Prefix-tuning的思想和应用场景，以及它如何解决一些NLP任务中的挑战**

**7.Lora的原理和存在的问题讲一下？**

**8.bf16，fp16半精度训练的优缺点**

**9.如何增加context length 模型训练中节约显存的技巧。**

**10.RLHF完整训练过程是什么？RL过程中涉及到几个模型？显存占用关系和SFT有什么区别？**

**11.RLHF过程中RM随着训练过程得分越来越高，效果就一定好吗？有没有极端情况？**

**12.encoder only，decoder only，encoder-decoder 划分的具体标注是什么？典型代表模型有哪些？**
